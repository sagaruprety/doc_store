{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e63f50",
   "metadata": {},
   "source": [
    "### The [langchain framework](https://python.langchain.com/docs/get_started/introduction.html) makes it easy to use LLMs as [agents](https://python.langchain.com/docs/modules/agents/) capable of making decisions. Furthermore, these agents can be equipped with a variety of [tools](https://python.langchain.com/docs/modules/agents/tools/) which implement different functionalities. LLM agents can be given access of a combination of such tools. The decision to use a particular tool as part of solving a particular task is based on the language understanding ability of the LLMs. \n",
    "\n",
    "\n",
    "### In this post, we will explore the power of Langchain agents and their application in question answering over a text document store. Specifically, we will dive into creating a Jupyter Notebook that demonstrates the integration of Large Language model (LLM) with external text documents and a search engine, enabling seamless information retrieval. We'll also discuss the challenges encountered during the planning phase and how to overcome them. In particular we discuss how to make agents use the tools in a particular order, whenever they decide to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe8870",
   "metadata": {},
   "source": [
    "### We start with installing and importing relevant libraries and setting up the openAI and SERP API keys. openAI API keys can be obtained from https://platform.openai.com/account/api-keys and SERP API keys can be obtained after registering at https://serpapi.com/. You can use an open source model like Llama2 instead. Langchain serves the functionality to load it via llama-cpp-python library.\n",
    "\n",
    "### You can clone the git repo: and run this notebook from within the repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have cloned the git repo, the requirements.txt file will list all required libraries\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c23659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import load_tools\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"your-serp-api-key\"\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898760d",
   "metadata": {},
   "source": [
    "## Connecting to a Document Store\n",
    "\n",
    "### Now that you have the OpenAI LLM model ready, let's move on to connecting it to documents and fetching data. To achieve this, we'll make use of Directory document loader available in Langchain. I have some text files stored in another directory in the same git repo. This can be replaced by any document store as a wiki/knowledge base, e.g. Confluence, Google Drive, S3 bucket, Any database, etc. Langchain has hunderds of [connectors](https://python.langchain.com/docs/modules/data_connection/document_loaders/) to third party document storage tools.\n",
    "\n",
    "\n",
    "### The documents I have used in this document store are notes of some LLM based papers I took while reading them, most of the time copying and pasting the text from those papers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b5668f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='ChatDoctor Paper\\n\\n\\nfine- tuned model based on 100k real-world patient-physician conversations from an online medical consultation site. \\n\\nAlso added  autonomous knowledge retrieval capabilities to our ChatDoctor, for ex- ample, Wikipedia or a database as a knowledge brain. \\n\\nCollected about 100k real doctor-patient conversations from an online medical consultation website HealthCareMagic1. We filtered these data both manually and automatically, removed the identity information of the doctor and patient, and used language tools to correct grammatical errors, and we named this dataset HealthCareMagic-100k.\\n\\nIn addition, we collected approximately 10k patient-physician conversations from the online medical consultation website iCliniq2 to evaluate the performance of our model.  \\n\\nFor Q&A in medical scenarios, we collected and compiled a database, partly sampled in Fig. 3, which includes about 700 diseases and their associated symptoms, further medical tests or measures, and recommended medications, as a gold standard for the medical profession. \\n\\nThe database can be updated at any time without retraining the model and can the- oretically be set up for a specific disease database depending on the department or specific target.\\n\\ncan refer to the disease databases and Wikipedia (or any other reliable information source) as external knowledge brains of our ChatDoctor. \\n\\nAfter constructing the external knowledge brain, we need to let our ChatDoctor retrieve the knowledge he needs autonomously, which can generally be achieved in a large language model by constructing appropriate prompts\\n\\nTo automate this process, we design keyword mining prompts (Fig. 4) for ChatDoc- tor to extract key terms for relevant knowledge seeking. \\n\\nThen, the top-ranked relevant passages were retrieved from Knowledge Brain with a term-matching retrieval system. \\n\\nAs for the disease database, since the model cannot read all the data at once, we first let the model read the data in batches and select for itself the data entries that might help answer the patient’s question ' metadata={'source': 'llm_papers/chat-doctor-paper-summary.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Loading the documents from a directory\n",
    "path = './llm_papers'\n",
    "loader = DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a79c7",
   "metadata": {},
   "source": [
    "### Now that we have the documents with us, we do some simple prompting to ask questions of the LLM through Chains.  Chains allow us to combine multiple components together to create a single, coherent application. For example, we can create a chain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by combining chains with other components.\n",
    "\n",
    "### Before that, we also need to do some standard operations - text splitting, embedding creation and indexing them in a vector store.\n",
    "\n",
    "### Often times your document is too long (like a book) for your LLM. You need to split it up into chunks. Text splitters help with this.There are many ways you could split your text into chunks, experiment with different ones to see which is best for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d253d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking the documents (splitting text into fixed size chunks)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6135f8",
   "metadata": {},
   "source": [
    "\n",
    "### Embeddings create a vector representation of a piece of text. This represents text in semantic or meaning space, so that pieces of text similar in meaning are near to each other in that space. \n",
    "\n",
    "### Vector databases provide an easy way to store the embedded text and perform the similarity search. We use Chromadb as the vector store here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a3d24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# vectorising documents based on these embeddings\n",
    "docsearch = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# creating a retrieval chain\n",
    "llm_papers = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b54138ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The REACT model is an approach that allows autonomous systems to generate reasoning traces and task-specific actions in an interleaved manner, enabling them to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting while also interacting with the external environments to incorporate additional information into reasoning.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Question answering over Confluence data\n",
    "query = \"What is the REACT model?\"\n",
    "llm_papers.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a5de004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The ChatDoctor paper works in the medical domain. It is based on 100k real-world patient-physician conversations from an online medical consultation site and has autonomous knowledge retrieval capabilities. It also collected about 100k real doctor-patient conversations from the online medical consultation website HealthCareMagic1 and approximately 10k patient-physician conversations from the online medical consultation website iCliniq2.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which paper works in medical domain?\"\n",
    "llm_papers.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00141a2",
   "metadata": {},
   "source": [
    "### But we want more than question answering based on the document stores. We may want to get information which may not be existing in the document store. With langchain, this can be done with tools and agents. Tools can interact with different sources of information and an agent can create the context from document store and decide which tool to use and how to use it with the given context.\n",
    "\n",
    "### Below I create a custom search tool which is an combination of two tools - one searches the  document store to answer the user query, and the other is the search engine result page (serp) api tool, which I want to use whenever some question cannot be answered with document store data.\n",
    "\n",
    "### Langchain Tool class takes in three parameters - name of the tool, the functionality of the tool and a description of the tool, which can be useful for an agent to decide when and how to use the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9e82046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defining search tool using SerpAPIWrapper\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "search_tool_default = [\n",
    "    Tool(\n",
    "        name = \"Document Store\",\n",
    "        func = llm_papers.run,\n",
    "        description = \"Use it to lookup information from the document store\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Use this to lookup information from google search engine\",\n",
    "    )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee04009",
   "metadata": {},
   "source": [
    "### Now we create an agent which will use the custom combined tool. We create a React zero shot agent, as we also get to see the reasoning behind sub-tool selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0fce4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look for a paper about AI with the title REACT.\n",
      "Action: Search\n",
      "Action Input: \"REACT paper AI\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for the authors of this paper.\n",
      "Action: Search\n",
      "Action Input: \"REACT paper AI authors\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mDownload a PDF of the paper titled ReAct: Synergizing Reasoning and Acting in Language Models, by Shunyu Yao and 6 other authors. PDF · Other ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The REACT paper in AI is titled ReAct: Synergizing Reasoning and Acting in Language Models, and is authored by Shunyu Yao and 6 other authors.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The REACT paper in AI is titled ReAct: Synergizing Reasoning and Acting in Language Models, and is authored by Shunyu Yao and 6 other authors.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an agent an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(search_tool_default , llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "agent.run(\"What is the REACT paper in AI about? Who are its authors?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abab3ed",
   "metadata": {},
   "source": [
    "### In the above result, we see that the agent takes the google search action, i.e. uses the SerpAPI tool all the time. We would like it to first lookup for information in the Document store first, before going to google.\n",
    "\n",
    "### So we specify this in the tool description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ef663b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new tool with order of tool usage made explicit\n",
    "\n",
    "search_tool_specify_order_in_dscrptn = [\n",
    "    Tool(\n",
    "        name = \"Document Store\",\n",
    "        func = llm_papers.run,\n",
    "        description = \"Use it to lookup information from document store. Always used as first tool\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Use this to lookup information from google search engine. \\\n",
    "        Use it only after you have tried using the document store tool.\",\n",
    "    )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a790ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look for the paper in the document store first.\n",
      "Action: Document Store\n",
      "Action Input: REACT paper in AI\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The ReAct paper is a research paper in the field of Artificial Intelligence that explores the potential of using large language models to improve the synergy between verbal reasoning and interactive decision making in autonomous systems. It proposes a new approach that allows the model to generate reasoning traces and task-specific actions in an interleaved manner, enabling it to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting while also interacting with the external environments to incorporate additional information into reasoning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for the authors of the paper.\n",
      "Action: Search\n",
      "Action Input: REACT paper in AI authors\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mYao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022). React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The authors of the REACT paper in AI are Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The authors of the REACT paper in AI are Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022).'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an agent which will use the modified tool\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(search_tool_specify_order_in_dscrptn , llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "# agent.agent.llm_chain.verbose=True\n",
    "# Now let's test it out!\n",
    "agent.run(\"What is the REACT paper in AI about? Who are its authors?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57fb95d",
   "metadata": {},
   "source": [
    "### This time the agent used the Document Store tool as the first action. Lets use it to answer more questions to see if it is consistent in following the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d91f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a paper and its authors\n",
      "Action: Search\n",
      "Action Input: \"medical domain paper authors\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAuthors and Contributors in Scientific and Medical Publications · Step 1: Establish an authorship working group early in the trial, · Step 2: ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find more specific information\n",
      "Action: Search\n",
      "Action Input: \"medical domain paper authors university\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mKeywords are important for indexing: they enable your manuscript to be more easily identified and cited. Check the GUIDE FOR AUTHORS for journal requirements.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Authors of papers in the medical domain should check the Guide for Authors of the journal they are submitting to for requirements regarding keywords and affiliations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Authors of papers in the medical domain should check the Guide for Authors of the journal they are submitting to for requirements regarding keywords and affiliations.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Which paper works in the medical domain? Which university are its authors affiliated to?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c2d2117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look for the paper in the document store\n",
      "Action: Document Store\n",
      "Action Input: Camel paper in LLMs\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m ReAct prompts LLMs to generate both verbal reasoning traces and actions pertaining to a task in an interleaved manner. This approach enables the model to perform dynamic reasoning, to create, maintain, and adjust high-level plans for acting, while also interacting with the external environments to incorporate additional information into reasoning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for more information about the paper\n",
      "Action: Search\n",
      "Action Input: Camel paper in LLMs\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and proposes a novel approach called ReAct (Reasoning and Action) that combines a language-based reasoning module with an action-based reasoning module. The proposed approach enables agents to reason and act in an interleaved manner, allowing them to dynamically adjust their plans and incorporate additional information into their reasoning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and proposes a novel approach called ReAct (Reasoning and Action) that combines a language-based reasoning module with an action-based reasoning module. The proposed approach enables agents to reason and act in an interleaved manner, allowing them to dynamically adjust their plans and incorporate additional information into their reasoning.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " agent.run(\"What is this new Camel paper in LLMs about. Give detailed summary of the paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dffc3",
   "metadata": {},
   "source": [
    "### We see that the agent is not consistent in following the order of tools specified in the tool description. This is because the final prompt which is sent to the model does not explicitly mention this order constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1f33a",
   "metadata": {},
   "source": [
    "### We need to make changes in the final prompt which is being sent to the model. This can be seen using 'agent.agent.llm_chain.prompt.template'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "116dfddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Document Store: Use it to lookup information from document store. Always used as first tool\n",
      "Search: Use this to lookup information from google search engine.         Use it only after you have tried using the document store tool.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Document Store, Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# let see what is final prompt which is being sent to the LLM\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602c231",
   "metadata": {},
   "source": [
    "### We see that although the tool description mentions that the agent should use Document Store as the first tool, it is still not sticking to this rule. We can instead make this rule explicit in the React method description part of the prompt. Specifically, we can mention it during the Action component of React."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f92cb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.agent.llm_chain.prompt.template = '''\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "Document Store: Use it to lookup information from document store. Always used as first tool\n",
    "Search: Use this to lookup information from google search engine. Use it only after you have tried using the document store tool.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [Document Store, Search]. Always look first in Document Store.\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe9e85",
   "metadata": {},
   "source": [
    "### Now let's see if making the small and simple change above can make the agent follow our tool order rule better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f27041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should look for the paper in the Document Store first.\n",
      "Action: Document Store\n",
      "Action Input: REACT paper in AI\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The ReAct paper is a research paper in the field of Artificial Intelligence that explores the potential of using large language models to improve the synergy between verbal reasoning and interactive decision making in autonomous systems. It proposes a new approach that allows the model to generate reasoning traces and task-specific actions in an interleaved manner, enabling it to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting while also interacting with the external environments to incorporate additional information into reasoning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe authors of the paper should be listed in the document.\n",
      "Action: Document Store\n",
      "Action Input: REACT paper in AI\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The ReAct paper is a research paper in the field of Artificial Intelligence that explores the potential of using large language models to improve the synergy between verbal reasoning and interactive decision making in autonomous systems. It proposes a new approach that allows the model to generate reasoning traces and task-specific actions in an interleaved manner, enabling it to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting while also interacting with the external environments to incorporate additional information into reasoning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe authors of the paper should be listed in the document.\n",
      "Action: Document Store\n",
      "Action Input: Authors of REACT paper in AI\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The authors of the ReAct paper in AI are not specified in the context given.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should search for the authors of the paper.\n",
      "Action: Search\n",
      "Action Input: Authors of REACT paper in AI\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe authors believe that ReAct can further unlock the potential of large language models in solving complex tasks that require both reasoning and decision-making capabilities. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022). React: Synergizing reasoning and acting in language models.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the authors of the paper.\n",
      "Final Answer: The authors of the REACT paper in AI are Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The authors of the REACT paper in AI are Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022).'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the REACT paper in AI about? Who are its authors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b488831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out which paper works in the medical domain and which university its authors are affiliated to.\n",
      "Action: Document Store\n",
      "Action Input: Paper works in the medical domain\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Yes, the paper is about a ChatDoctor model that is fine-tuned based on 100k real-world patient-physician conversations from an online medical consultation site. It also has autonomous knowledge retrieval capabilities, such as Wikipedia or a database as a knowledge brain. The paper also collected about 100k real doctor-patient conversations from the online medical consultation website HealthCareMagic1 and approximately 10k patient-physician conversations from the online medical consultation website iCliniq2 to evaluate the performance of the model.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find out which university the authors are affiliated to.\n",
      "Action: Search\n",
      "Action Input: Authors of ChatDoctor paper\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mOur proposed ChatDoctor, represents a significant advancement in medical LLMs, ... Which authors of this paper are endorsers?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe authors of the paper are affiliated to the University of California, Berkeley.\n",
      "Final Answer: The paper works in the medical domain and its authors are affiliated to the University of California, Berkeley.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The paper works in the medical domain and its authors are affiliated to the University of California, Berkeley.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Which paper works in the medical domain? Which university are its authors affiliated to?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a76d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should first look in the Document Store to see if I can find the paper.\n",
      "Action: Document Store\n",
      "Action Input: Camel paper in LLMs\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m ReAct prompts LLMs to generate both verbal reasoning traces and actions pertaining to a task in an interleaved manner. This approach enables the model to perform dynamic reasoning, to create, maintain, and adjust high-level plans for acting, while also interacting with the external environments to incorporate additional information into reasoning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should now search for more information about the paper\n",
      "Action: Search\n",
      "Action Input: Summary of Camel paper in LLMs\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their \"cognitive\" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The Camel paper in LLMs proposes a novel communicative agent framework named role-playing to facilitate autonomous cooperation among communicative agents and provide insight into their \"cognitive\" processes. The framework enables the model to perform dynamic reasoning, to create, maintain, and adjust high-level plans for acting, while also interacting with the external environments to incorporate additional information into reasoning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Camel paper in LLMs proposes a novel communicative agent framework named role-playing to facilitate autonomous cooperation among communicative agents and provide insight into their \"cognitive\" processes. The framework enables the model to perform dynamic reasoning, to create, maintain, and adjust high-level plans for acting, while also interacting with the external environments to incorporate additional information into reasoning.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets query about a topic which doesn't exist in the document store.\n",
    "agent.run(\"What is this new Camel paper in LLMs about. Give detailed summary of the paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec73da7",
   "metadata": {},
   "source": [
    "### We now find the agent is more consistent in following the order of tools - firstly looking up the answer in the document store and only going to google search if it doesn't find anything with the first tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ebf18",
   "metadata": {},
   "source": [
    "### There are still some problems with the final responses we get, especially the university affiliations for the chat doctor paper is wrong. That can be addressed by analysing and processing the response we get from the serp-api. We will see how to parse and validate the output in another blog. This blog was about using multiple tools with an LLM agent and adding some order constraints to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf7238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
