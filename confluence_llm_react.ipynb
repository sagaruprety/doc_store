{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e63f50",
   "metadata": {},
   "source": [
    "### In this post, we will explore the power of Langchain agents and their application in question answering over a text document store. Specifically, we will dive into creating a Jupyter Notebook that demonstrates the integration of Langchain agents with Confluence pages, enabling seamless information retrieval. We'll also discuss the challenges encountered during the planning phase and how to overcome them.\n",
    "\n",
    "### The [langchain framework](https://python.langchain.com/docs/get_started/introduction.html) makes it easy to use Large Language Models (LLMs) as [agents](https://python.langchain.com/docs/modules/agents/) capable of making decisions. Furthermore, these agents can be equipped with a variety of [tools](https://python.langchain.com/docs/modules/agents/tools/) which implement different functionalities. LLM agents can be given access of a combination of such tools. The decision to use a particular tool as part of solving a particular task is based on the language understanding ability of the LLMs. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe8870",
   "metadata": {},
   "source": [
    "### We start with installing and importing relevant libraries and setting up the openAI and SERP API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain atlassian-python-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c23659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.document_loaders import ConfluenceLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import load_tools\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"b4b1d59017daf45a63fcad672a4b4ce8e23bb3ad7f9cf7365956191e23c302a1\"\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898760d",
   "metadata": {},
   "source": [
    "### Connecting to Confluence\n",
    "Now that you have the OpenAI LLM model ready, let's move on to connecting it to documents and fetching data. To achieve this, we'll make use of Confluence document loader available in Langchain. Confluence is a widely used collaboration and documentation software. It's designed to help teams work together, share information, and create and organize content in a collaborative digital environment. This tutorial utilises Confluence as a wiki/knowledge base because it is particularly popular in enterprise teams for its ability to facilitate knowledge sharing and communication. \n",
    "\n",
    "Using Langchain's ConfluenceLoader class, we can load the documents from Confluence. There are some dummy documents created at https://confluence-llm.atlassian.net/wiki . You need to create an account in Confluence in order to access this page.\n",
    "\n",
    "\n",
    "Accessing Confluence Data Loaders in Langchain: Langchain provides built-in data loaders to fetch data from various sources, including Confluence. Initialize a Confluence data loader instance by providing your Confluence username, api key, and the Confluence space or page URL you want to extract data from.\n",
    "\n",
    "All info related to loading data from confluence can be found at: https://python.langchain.com/docs/integrations/document_loaders/confluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5668f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'404: Not Found'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = 'https://github.com/sagaruprety/doc_store/blob/ad04f32356ad9c437ca4621fb0bbd32a1b888991/llm_papers/Emergent-ability-llm-summary.txt'\n",
    "# url = 'https://raw.githubusercontent.com/netology-code/py-homework-basic-files/master/3.2.http.requests/DE.txt'\n",
    "resp = requests.get(url)\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67638e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting with Confluence API\n",
    "# api_key can be created and managed at https://id.atlassian.com/manage-profile/security/api-tokens\n",
    "\n",
    "loader = ConfluenceLoader(\n",
    "    url=\"https://confluence-llm.atlassian.net/wiki\",\n",
    "    username=\"sagaruprety@gmail.com\",\n",
    "    api_key=\"ATATT3xFfGF0TTnRi9V1HT_JYruA4NwoP0AmYseisVgE0ZB5_aMf2p-Gf88vvZcaKbkraPrB1WCZalWtOYOyrcxX50IR8PHOzmGNgv6mJ683z_eJG1qM9EGR1i86kz4x5wTQ_Tcecd9rV2n2IIq0DQ0i3Bdkq2iNgNVXduq0hnAbdFaWxLHBvQY=73F405A7\"\n",
    ")\n",
    "\n",
    "# space_key refers to the specific page within Confluence you wish to load documents from.\n",
    "# It can found at https://yoursite.atlassian.com/wiki/spaces/<space_key>/pages/<page_id>\n",
    "documents = loader.load(space_key=\"~5e91dc845f62040b813a19da\", limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54138ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleÂ Question answering over Confluence data\n",
    "query = \"What is the REACT model?\"\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "qa_chain.run(input_documents=documents, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5de004",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which paper works in medical domain?\"\n",
    "qa_chain.run(input_documents=documents, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00141a2",
   "metadata": {},
   "source": [
    "### Below I create a custom search tool which is an combination of two tools - one searches the confluence data store to answer the user query, and the other is the search engine result page (serp) api tool, which I want to use whenever some question cannot be answered with confluence data.\n",
    "\n",
    "### Langchain Tool class takes in three parameters - name of the tool, the functionality of the tool and a description of the tool, which can be useful for an agent to decide when and how to use the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e82046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom search tool using with basic descriptions\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# defining search tool using confluence document store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)\n",
    "confluence_ml_papers = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())\n",
    "\n",
    "# defining search tool using SerpAPIWrapper\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "search_tool_default = [\n",
    "    Tool(\n",
    "        name = \"Confluence ML Papers wiki\",\n",
    "        func = confluence_ml_papers.run,\n",
    "        description = \"Use it to lookup information from Confluence pages\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Use this to lookup information from google search engine\",\n",
    "    )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee04009",
   "metadata": {},
   "source": [
    "### Now we create an agent which will use the custom combined tool. We create a React zero shot agent, as we also get to see the reasoning behind sub-tool selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fce4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an agent which will use the custom tool\n",
    "\n",
    "# serp_tools = load_tools([\"serpapi\"], confluence_tool )\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(search_tool_default , llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "# agent.agent.llm_chain.verbose=True\n",
    "# Now let's test it out!\n",
    "agent.run(\"What is the REACT paper in AI about? Who are its authors?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abab3ed",
   "metadata": {},
   "source": [
    "### In the above result, we see that the agent takes the google search action, i.e. uses the SerpAPI tool all the time. We would like it to first lookup for information in the Confluence data base first, before going to google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef663b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom search tool using with information about order of usage in descriptions\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# defining search tool using confluence document store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)\n",
    "confluence_ml_papers = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())\n",
    "\n",
    "# defining search tool using SerpAPIWrapper\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "search_tool_specify_order_in_dscrptn = [\n",
    "    Tool(\n",
    "        name = \"Confluence ML Papers wiki\",\n",
    "        func = confluence_ml_papers.run,\n",
    "        description = \"Use it to lookup information from Confluence pages. Always used as first tool\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Use this to lookup information from google search engine. \\\n",
    "        Use it only after you have tried using the Confluence ML Papers wiki tool.\",\n",
    "    )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an agent which will use the custom tool\n",
    "\n",
    "# serp_tools = load_tools([\"serpapi\"], confluence_tool )\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(search_tool_specify_order_in_dscrptn , llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "# agent.agent.llm_chain.verbose=True\n",
    "# Now let's test it out!\n",
    "agent.run(\"What is the REACT paper in AI about? Who are its authors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Which paper works in the medical domain? Which university are its authors affiliated to?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d2117",
   "metadata": {},
   "outputs": [],
   "source": [
    " agent.run(\"What is this new Camel paper in LLMs about. Give detailed summary of the paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1f33a",
   "metadata": {},
   "source": [
    "### We need to make changes in the final prompt which is being sent to the model. This can be seen using 'agent.agent.llm_chain.prompt.template'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92cb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.agent.llm_chain.prompt.template = '''Answer the following questions as best you can. \\n\n",
    "You have access to the following tools:\\n\\n\n",
    "Confluence ML Papers : Always used as first tool\\n\n",
    "Search: Always used after Confluence ML Papers wiki tool. Useful only when you do not find the answer in Confluence ML Papers wiki.\\n\\n\n",
    "Action input should include as much context as possible.\\n\\n\n",
    "Use terms from the observation of first tool as input to the search tool.\n",
    "\n",
    "Question: the input question you must answer\\nThought: you should always think about what to do\\n\n",
    "Action: the action to take, should be one of [Confluence ML Papers wiki, Search]. Always look first in Confluence ML Papers wiki\\n\n",
    "Action Input: the input to the action\\n\n",
    "Observation: the result of the action\\n\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\\n\n",
    "Thought: I now know the final answer\\n\n",
    "Final Answer: the final answer to the original input question\\n\\n\n",
    "Begin!\\n\\n\n",
    "Question: {input}\\n\n",
    "Thought:{agent_scratchpad}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"What is the REACT paper in AI about? Who are its authors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Which paper works in the medical domain? Which university are its authors affiliated to?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    " agent.run(\"What is this new Camel paper in LLMs about. Give detailed summary of the paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ca4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1b122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
